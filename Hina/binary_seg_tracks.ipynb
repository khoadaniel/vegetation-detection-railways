{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import random\n",
    "\n",
    "from transformers import DPTFeatureExtractor, DPTForDepthEstimation\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image,ImageFilter\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these codes are used to loop through the directory\n",
    "path_images = 'rs19_val/jpgs/rs19_val/'\n",
    "path_images_resized = 'rs19_val/960_512/images_resized/'\n",
    "path_masks = 'rs19_val/uint8/rs19_val/'\n",
    "path_masks_resized = 'rs19_val/960_512/masks_resized_track/'\n",
    "\n",
    "\n",
    "# read the tram list and turn it into a dict\n",
    "tram_list = pd.read_csv('tram_filenames.csv')\n",
    "tram_dict = tram_list.iloc[:,1:].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel labels for each class\n",
    "tram_track=3 \n",
    "rail_track=12\n",
    "track_bed= 15\n",
    "rail_raised= 17\n",
    "rail_embedded =18\n",
    "veg = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the mask label containing 5 labels related to tracks\n",
    "\n",
    "- 200 tram images \n",
    "- Input images and Masks -> resized (NN) 512x256 , Median filter\n",
    "- Prepare Binary Masks for all 5 options of labels related to track identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_resized = []\n",
    "masked_dataset_resized = []\n",
    "\n",
    "down_width = 960\n",
    "down_height = 512\n",
    "down_points = (down_width, down_height)\n",
    "\n",
    "for i in range(len(tram_list)):\n",
    "    image_tram = cv2.imread(path_images+tram_dict['filename_jpg'][i],1)\n",
    "    mask_tram =  cv2.imread(path_masks+tram_dict['filename_mask'][i],0)\n",
    "    # Median filter 3x3 and resizing 960x512 (such that the dimensions are divisible by 32 becuase of model requiremnet)\n",
    "    #resize the input image by a scale factor using k-nearest interpolation such that the dimensions are divisible by 32\n",
    "    #image_tram= image_tram.filter(ImageFilter.MedianFilter(size= 3))\n",
    "    image_tram = cv2.medianBlur(image_tram, 3)\n",
    "    image_resized= cv2.resize(image_tram, down_points, interpolation= cv2.INTER_NEAREST)\n",
    "\n",
    "    cv2.imwrite(path_images_resized+tram_dict['filename_jpg'][i]+'.jpg', image_resized)\n",
    "    image_dataset_resized.append(image_resized)\n",
    "\n",
    "    #repeat for masks\n",
    "    #mask_tram= mask_tram.filter(ImageFilter.MedianFilter(size= 3))\n",
    "    mask_tram=cv2.medianBlur(mask_tram, 3)\n",
    "    mask_resized= cv2.resize(mask_tram, down_points, interpolation= cv2.INTER_NEAREST)\n",
    " \n",
    "    # Binary masks for track\n",
    "    for k,val in enumerate(mask_resized):\n",
    "        for j,val1 in enumerate(val):\n",
    "            if (val1==tram_track or val1== rail_track or val1==rail_embedded or val1==rail_raised or val1== track_bed):\n",
    "                val[j] = 1\n",
    "            else:\n",
    "                val[j] = 0\n",
    "    \n",
    "    masked_dataset_resized.append(mask_resized)\n",
    "    cv2.imwrite(path_masks_resized+tram_dict['filename_mask'][i]+'.png', mask_resized)\n",
    "\n",
    "image_dataset_resized = np.array(image_dataset_resized)\n",
    "masked_dataset_resized = np.array(masked_dataset_resized)\n",
    "\n",
    "#pickle.dump(image_dataset_resized, open('image_dataset_resized_10', \"wb\"))\n",
    "#pickle.dump(masked_dataset_resized, open('mask_dataset_10', \"wb\"))\n",
    "#pickle.dump(dataset_mask_multiplied, open('dataset_roi_mask_10', \"wb\"))\n",
    "\n",
    "print(image_resized.shape)\n",
    "print(mask_resized.shape)\n",
    "print(image_dataset_resized.shape)\n",
    "print(masked_dataset_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ['rs00079','rs01562','rs02536','rs03764','rs04744','rs05410','rs07603','rs08095']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_width = 960\n",
    "down_height = 512\n",
    "down_points = (down_width, down_height)\n",
    "\n",
    "for imgfile in range(len(test_list)):\n",
    "    chk_img= cv2.imread(path_images_resized+test_list[imgfile]+'.jpg')\n",
    "    \n",
    "    chk_msk= cv2.imread(path_masks_resized+test_list[imgfile]+'.jpg')\n",
    "\n",
    "\n",
    "    org_msk = cv2.imread(path_masks+test_list[imgfile]+'png',0)\n",
    "    org_msk = cv2.medianBlur(org_msk,3)\n",
    "    org_msk = cv2.resize(org_msk, down_points, interpolation= cv2.INTER_NEAREST)\n",
    "\n",
    "    figure, axis_arr = plt.subplots(1,3, figsize=(20,20)) \n",
    "    axis_arr[0].imshow(chk_img)\n",
    "    axis_arr[0].get_title('image_resized')\n",
    "    axis_arr[1].imshow(org_msk, cmap='prism')\n",
    "    axis_arr[1].get_title('mask_original_resized')\n",
    "    axis_arr[2].imshow(chk_msk, cmap='prism')\n",
    "    axis_arr[2].get_title('mask_resized_track')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08c0539bf10c75c5b2836a432ee34201d271197da8458066aa86299ab8bcd438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
